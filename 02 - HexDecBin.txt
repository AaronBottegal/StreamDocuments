About binary, decimal, and hexidecimal:
=======================================

Decimal, Hexadecimal, and Binary are all just ways to represent numbers.

Binary (Bin, denoted by 0b or #%) is what computers use. Each digit (A "bit") has 2 possibilities:
0 or 1

Decimal (Dec) is what humans use. 1-10. Each digit has 10 possibilities:
0,1,2,3,4,5,6,7,8,9

Hexadecimal (Hex, denoted by 0x or #$) has 16 possibilities.
To represent them in one character, we add letters as "values":
0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F

The values created with each are all equivelents to each other, just represented differently. E.g. #%1010 = #$0A = #10

Computers work in bits because the gates that make them work can be either on (1) or off (0), so binary is a natural way to represent numbers in computers.

To represent values larger than 0 or 1, computers use multiple bits together in a group.

8 bits together are called a "byte". 16 together is called a "word". 32 is called a "dword" (double word). 4 bits is also called a "nibble".

Binary and bits are especially important to understand, because microprocessors work with
"registers" to store values to tell the system how to operate. Some of the values
are really multiple single bits being enabled/disabled that do different things.
What might be represented as #$80 (128, %1000 0000) in code could represent enabling one bit as shown in binary.

To find how many values you can hold in X bits is 2^X.
E.g. 8 bits can hold 256 numbers.
16 bits can hold 65536 numbers.
32 bits can hold 4294967296 numbers.

Because 0 counts as the first combination, the range is actually one less than the total number of combinations.
E.g. 8 bits: 0 to 255
16 bits: 0 to 65535
32 bits: 0 to 4294967295

HEX/DEC/BIN Conversion chart:
Keep this around for fast binary to hex conversions.

+-----+-----+------+
| DEC | HEX |  BIN |
|------------------|
|   0 |   0 | 0000 |
|   1 |   1 | 0001 | (Bit 0 set to 1, aka +1)
|   2 |   2 | 0010 | (Bit 1 set to 1, aka +2)
|   3 |   3 | 0011 |
|   4 |   4 | 0100 | (Bit 2 set to 1, aka +4)
|   5 |   5 | 0101 |
|   6 |   6 | 0110 |
|   7 |   7 | 0111 |
|   8 |   8 | 1000 | (Bit 3 set to 1, aka +8)
|   9 |   9 | 1001 |
|  10 |   A | 1010 |
|  11 |   B | 1011 |
|  12 |   C | 1100 |
|  13 |   D | 1101 |
|  14 |   E | 1110 |
|  15 |   F | 1111 |
+-----+-----+------+


Bit fields
==========

One important idea to know of is that values represented as decimal or hex might actually have binary significance.

This is important because many times, a byte may contain many settings of a couple bits each.
E.g. Turning on or off a single feature (1 bit), or setting something to one of 7 states (3 bits), etc.

Bit fields are also important in computer math, which we will touch on now with signed numbers in the next lesson.
