About binary, decimal, and hexidecimal:
=======================================

Any questions about anything, ask in chat!

Decimal, Hexadecimal, and Binary are all just ways to represent values (numbers).

Binary (Bin, denoted by 0b or %) is what computers use. Each digit (A "bit") has 2 possibilities:
0,1

Decimal (Dec) is what humans use. 1-10. Each digit has 10 possibilities:
0,1,2,3,4,5,6,7,8,9

Hexadecimal (Hex, denoted by 0x or $) has 16 possibilities, hence, HEX-a-DECIMAL.
To represent them in one character, we add letters as "values":
0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F

The values created with each are all equivelents to each other, just represented differently.

Computers work in bits because the gates that make them work can be either on (1) or off (0).

To represent values larger than 0 or 1, computers use multiple bits together in a group.

8 bits together are called a "byte". 16 together is called a "word". 32 is called a "dword" (double word).

Each of the above representations can add more characters to represent bigger values.

Binary and bits are especially important to understand, because microprocessors work with
"registers" to store values to tell the system how to operate. Some of the values
are really multiple single bits being enabled/disabled that do different things.
What might be represented as #$80 (128, %1000 0000) in code could represent enabling one bit as shown in binary.

To find how big an unsigned value you can hold in X bits is (2^X)-1.
Using that formula, a 32 bit (4 byte, 2 word, 1 dword) processor can hold from 0 to 4294967295.
16-bit holds 0 to 65535.
8-bit holds 0-255.

All this info is used to understand what is being represented. A majority of the
time, the value is just that, a value. But it could also might be representing binary bits
to tell the system how to operate.


Another important idea is how there's two ways to think about binary numbers, called the sign.
If adding %0001 to %1111, the results is 0000. But if adding %1111 to %1111, the result is %1110.
This is effectively a subtraction. This idea is where signed numbers come from. Basically, the
highest bit in a number because a flag for positive/negative, so adding a value can also
be though of of a subtraction. E.g. Adding %11111111 in an 8-bit value is the same as -1.

Here are the ranges for each value bit length, if thought of as signed.
8-bit signed values range from -128 [%1000 0000] to +127 [%0111 1111])
16-bit signed values range from -32768 to 32767.
32-bit signed values range from -2,147,483,648 to 2,147,483,647

The reason why the negative number is always larger is because 0 is a positive number,
meaning there's one less "positive" value that isn't 0.


HEX/DEC/BIN Conversion chart:
Keep this around for fast binary to hex conversions.

+-----+-----+------+
| DEC | HEX |  BIN |
|------------------|
|   0 |   0 | 0000 |
|   1 |   1 | 0001 | (Bit 0 set to 1, aka +1)
|   2 |   2 | 0010 | (Bit 1 set to 1, aka +2)
|   3 |   3 | 0011 |
|   4 |   4 | 0100 | (Bit 2 set to 1, aka +4)
|   5 |   5 | 0101 |
|   6 |   6 | 0110 |
|   7 |   7 | 0111 |
|   8 |   8 | 1000 | (Bit 3 set to 1, aka +8)
|   9 |   9 | 1001 |
|  10 |   A | 1010 |
|  11 |   B | 1011 |
|  12 |   C | 1100 |
|  13 |   D | 1101 |
|  14 |   E | 1110 |
|  15 |   F | 1111 |
+-----+-----+------+